{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "split_and_save_data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L-Xam-rG-3b",
        "colab_type": "text"
      },
      "source": [
        "**This code is for allowing us to download Kaggle data in Google Colab.**\n",
        "\n",
        "Before you execute the code in the following cell, you need to follow these two steps:\n",
        "-1.  Go to your Kaggle account, Scroll to API section and Click Expire API Token to remove previous tokens. \n",
        "\n",
        "-2. Click on Create New API Token - It will download kaggle.json file on your machine."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IanswNtVUmKw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install kaggle\n",
        "! pip install -q kaggle\n",
        "\n",
        "# Upload the kaggle.json file that you downloaded locally\n",
        " from google.colab import files\n",
        " files.upload()\n",
        "\n",
        "# Make directory named kaggle and copy kaggle.json file there\n",
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "# Change the permissions of the file\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download the dataset we need: ASL Alphabet\n",
        "!kaggle datasets download -d grassknoted/asl-alphabet\n",
        "\n",
        "# Unzip your downloaded dataset\n",
        "!unzip asl-alphabet.zip -d asl-alphabet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HPlzE38UZQI",
        "colab_type": "text"
      },
      "source": [
        "**The following code also needs to be run only once. It is for connecting Colab to your Google Drive. When running this cell you will be given a password and you need to enter it here.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYjKJzZ_Ufby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLuZKOVvLu6q",
        "colab_type": "text"
      },
      "source": [
        "**The code from the rest of the cells reads all photos and the associated class labels from the dataset into numpy arrays, splits them into training and testing set and finally, saves them into a .h5 file.**\n",
        "\n",
        "Declaring some constant values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjuANAD5ahe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLASSES = ['A', 'B', 'C', 'D', 'del', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'nothing', 'O', 'P', 'Q', 'R', 'S', 'space',\n",
        "           'T', 'U', 'V', 'W', 'X', 'Y', 'Z']\n",
        "TRAINING_DATA_FOLDER = 'asl-alphabet/asl_alphabet_train/asl_alphabet_train/'\n",
        "NUMBER_OF_CLASSES = 29\n",
        "SPLIT_RATIO = 0.1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pok4k7eMN2PT",
        "colab_type": "text"
      },
      "source": [
        "**We use the TrainingDataReader class to read images. **\n",
        "\n",
        "Initially we only read them into the training_data and training_class_labels attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hi4--Fy4XfN0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2 as cv\n",
        "\n",
        "\n",
        "class TrainingDataReader:\n",
        "\n",
        "    def __init__(self):\n",
        "      \"\"\"\n",
        "      attributes:\n",
        "      training_data: contains data that we will use to train our model\n",
        "      training_class_labels: actual classes that each training sample belongs to\n",
        "      testing_data: contains data that we will use to test the accuracy of our trained model\n",
        "      testing_class_labels: actual classes that each testing sample belongs to\n",
        "      \"\"\"\n",
        "        self.number_of_classes = NUMBER_OF_CLASSES\n",
        "        self.training_data = np.zeros(shape=(int((1 - SPLIT_RATIO) * 87000), 64, 64, 3), dtype='float32')\n",
        "        self.training_class_labels = np.zeros(shape= int((1 - SPLIT_RATIO) * 87000), dtype='uint8')\n",
        "        self.testing_data = np.zeros(shape=(int(SPLIT_RATIO * 87000), 64, 64, 3), dtype='float32')\n",
        "        self.testing_class_labels = np.zeros(shape=int(SPLIT_RATIO * 87000), dtype='uint8')\n",
        "\n",
        "    def read_training_data(self):\n",
        "      \"\"\"\n",
        "      Obtains folder with data from the next class and calls 'read_data_for_one_class' to actually read the data\n",
        "      \"\"\"\n",
        "        for category in CLASSES:\n",
        "            path = os.path.join(TRAINING_DATA_FOLDER, category)\n",
        "            class_num = CLASSES.index(category)\n",
        "            self.read_data_for_one_class(path, class_num)\n",
        "\n",
        "    def read_data_for_one_class(self, path, class_num):\n",
        "      \"\"\"\n",
        "      Main method of this first part of the project.\n",
        "      This method gets the path to a folder belonging to one class, iterates through the photos, reads them,\n",
        "      normalizes them and adds them to the training data, as well as the corresponding class labels.\n",
        "      \"\"\"\n",
        "            print('Currently reading data for class number {}...'.format(class_num))\n",
        "            counter = class_num * 3000\n",
        "            for image in os.listdir(path):\n",
        "                try:\n",
        "                    image_array = cv.imread(os.path.join(path, image), cv.IMREAD_COLOR)\n",
        "                    new_array = cv.resize(image_array, (64, 64))\n",
        "\n",
        "                    self.training_data[counter] = cv.normalize(new_array, None, alpha=0, beta=1, norm_type=cv.NORM_MINMAX, dtype=cv.CV_32F)\n",
        "                    self.training_class_labels[counter] = class_num\n",
        "                    counter = counter + 1\n",
        "                except Exception as e:\n",
        "                    pass\n",
        "                    \n",
        "training_data_reader = TrainingDataReader()\n",
        "training_data_reader.read_training_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsSVzgQOS5Ul",
        "colab_type": "text"
      },
      "source": [
        "I had some problems installing sklearn here, but these lines of code solved the problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ootvY4EgqcI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip uninstall sklearn -y\n",
        "!pip install Cython\n",
        "!pip install https://github.com/Santosh-Gupta/scikit-learn/archive/master.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_vVvqIxTTRB",
        "colab_type": "text"
      },
      "source": [
        "Using sklearn's train_test_split method we will split our original data into training and testing set. It is very important to also note that this method shuffles the data by default. This is something that will be crucial to obtain a high accuracy not only on the training data, but on the validation data as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GDHgbbApU2Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "training_data_reader.training_data, training_data_reader.testing_data, \\\n",
        "training_data_reader.training_class_labels, training_data_reader.testing_class_labels = \\\n",
        "train_test_split(training_data_reader.training_data, training_data_reader.training_class_labels, test_size = SPLIT_RATIO)\n",
        "\n",
        "print('Splitting has been completed.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31Sh_22vTpYU",
        "colab_type": "text"
      },
      "source": [
        "Run this next cell to save your data in a file called hra_training_data.h5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itUye5tLs5Bv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File('hra_training_data.h5', 'w') as hf:\n",
        "  hf.create_dataset(\"training_data\", data=training_data_reader.training_data)\n",
        "  hf.create_dataset(\"training_class_labels\", data=training_data_reader.training_class_labels)\n",
        "  hf.create_dataset(\"testing_data\", data=training_data_reader.testing_data)\n",
        "  hf.create_dataset(\"testing_class_labels\", data=training_data_reader.testing_class_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiGnjQs4Vfcl",
        "colab_type": "text"
      },
      "source": [
        "Run this last cell in order to copy your data to your Google drive (make sure first that you mounted your drive).\n",
        "\n",
        "After the copying is done, from your Google drive you can save the file locally. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6llsem23tnZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!cp hra_training_data.h5 \"drive/My Drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}